{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b172a362",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d88bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ea02bc",
   "metadata": {},
   "source": [
    "## Load preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33073521",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"PreprocessedRealFake.csv\")\n",
    "data = data[(~data[\"text\"].isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b67141",
   "metadata": {},
   "source": [
    "## Split data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "199f67bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train,X_test,y_train,y_test = train_test_split(data['text'], data.target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa60e0b4",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "add8d3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  73.33%\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        real       0.74      0.73      0.74     16006\n",
      "        fake       0.73      0.74      0.73     15489\n",
      "\n",
      "    accuracy                           0.73     31495\n",
      "   macro avg       0.73      0.73      0.73     31495\n",
      "weighted avg       0.73      0.73      0.73     31495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sv = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('model', svm.SVC(kernel='linear',\n",
    "                                 C=1.0,\n",
    "                                 max_iter=100))])\n",
    "\n",
    "sv_model = sv.fit(X_train, y_train)\n",
    "\n",
    "sv_pred = sv_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy_score(y_test, sv_pred)*100,2), \"\\b%\")\n",
    "print(\"Classification Report:\\n\\n\", classification_report(y_test, sv_pred, labels=[\"real\", \"fake\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf8da61",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a6d078f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  86.66%\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        real       0.91      0.81      0.86     16006\n",
      "        fake       0.83      0.92      0.87     15489\n",
      "\n",
      "    accuracy                           0.87     31495\n",
      "   macro avg       0.87      0.87      0.87     31495\n",
      "weighted avg       0.87      0.87      0.87     31495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('model', MultinomialNB(alpha=1.0,\n",
    "                                       fit_prior=True,\n",
    "                                       class_prior=None))])\n",
    "\n",
    "nb_model = nb.fit(X_train, y_train)\n",
    "\n",
    "nb_pred = nb_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy_score(y_test, nb_pred)*100,2), \"\\b%\")\n",
    "print(\"Classification Report:\\n\\n\", classification_report(y_test, nb_pred, labels=[\"real\", \"fake\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6cc201",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90a3b4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  95.0%\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        real       0.94      0.96      0.95     16006\n",
      "        fake       0.96      0.94      0.95     15489\n",
      "\n",
      "    accuracy                           0.95     31495\n",
      "   macro avg       0.95      0.95      0.95     31495\n",
      "weighted avg       0.95      0.95      0.95     31495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('model', LogisticRegression(penalty='l2',\n",
    "                                            C=1,\n",
    "                                            solver='lbfgs',\n",
    "                                            max_iter=1000,\n",
    "                                            class_weight='balanced'))])\n",
    "\n",
    "lr_model = lr.fit(X_train, y_train)\n",
    "\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy_score(y_test, lr_pred)*100,2), \"\\b%\")\n",
    "print(\"Classification Report:\\n\\n\", classification_report(y_test, lr_pred, labels=[\"real\", \"fake\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75536a8b",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4db08ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  80.35%\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        real       0.89      0.70      0.78     16006\n",
      "        fake       0.75      0.91      0.82     15489\n",
      "\n",
      "    accuracy                           0.80     31495\n",
      "   macro avg       0.82      0.81      0.80     31495\n",
      "weighted avg       0.82      0.80      0.80     31495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kn = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('model', KNeighborsClassifier(n_neighbors=5))])\n",
    "\n",
    "kn_model = kn.fit(X_train, y_train)\n",
    "\n",
    "kn_pred = kn_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy_score(y_test, kn_pred)*100,2), \"\\b%\")\n",
    "print(\"Classification Report:\\n\\n\", classification_report(y_test, kn_pred, labels=[\"real\", \"fake\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f12690e",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99b1e532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  93.98%\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        real       0.93      0.96      0.94     16006\n",
      "        fake       0.95      0.92      0.94     15489\n",
      "\n",
      "    accuracy                           0.94     31495\n",
      "   macro avg       0.94      0.94      0.94     31495\n",
      "weighted avg       0.94      0.94      0.94     31495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', DecisionTreeClassifier(criterion= 'gini',\n",
    "                                           max_depth = 100, \n",
    "                                           splitter='best', \n",
    "                                           random_state=42))])\n",
    "dtc_model = dtc.fit(X_train, y_train)\n",
    "\n",
    "dtc_pred = dtc_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", round(accuracy_score(y_test, dtc_pred)*100,2), \"\\b%\")\n",
    "print(\"Classification Report:\\n\\n\", classification_report(y_test, dtc_pred, labels=[\"real\", \"fake\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6084f3",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0264b9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 96.11%\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        real       0.96      0.97      0.96     16006\n",
      "        fake       0.96      0.96      0.96     15489\n",
      "\n",
      "    accuracy                           0.96     31495\n",
      "   macro avg       0.96      0.96      0.96     31495\n",
      "weighted avg       0.96      0.96      0.96     31495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', RandomForestClassifier(n_estimators=100,\n",
    "                                                  criterion=\"entropy\"))])\n",
    "\n",
    "rfc_model = rfc.fit(X_train, y_train)\n",
    "rfc_pred = rfc_model.predict(X_test)\n",
    "print(\"accuracy:\", round(accuracy_score(y_test, rfc_pred)*100,2), \"\\b%\")\n",
    "print(\"Classification Report:\\n\\n\", classification_report(y_test, rfc_pred, labels=[\"real\", \"fake\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13129b5b",
   "metadata": {},
   "source": [
    "## Store the model names and their accuracy in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8239ccad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>96.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>95.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>93.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>86.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>80.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>73.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                models  accuracy\n",
       "0        Random Forest     96.11\n",
       "1  Logistic Regression     95.00\n",
       "2        Decision Tree     93.98\n",
       "3          Naive Bayes     86.66\n",
       "4                  KNN     80.35\n",
       "5                  SVM     73.33"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "res = pd.DataFrame(res)\n",
    "res[\"models\"] = [\"SVM\", \"Naive Bayes\", \"Logistic Regression\", \"KNN\", \"Decision Tree\", \"Random Forest\"]\n",
    "res[\"accuracy\"] = [round(accuracy_score(y_test, sv_pred)*100,2), round(accuracy_score(y_test, nb_pred)*100,2), round(accuracy_score(y_test, lr_pred)*100,2), round(accuracy_score(y_test, kn_pred)*100,2), round(accuracy_score(y_test, dtc_pred)*100,2), round(accuracy_score(y_test, rfc_pred)*100,2)]\n",
    "res = res.sort_values(\"accuracy\", ascending=False).reset_index(drop=True)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4397c2a",
   "metadata": {},
   "source": [
    "## Prediction based on user input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de73ccfb",
   "metadata": {},
   "source": [
    "Take user input, and store predicted value by each model in the `res` dataframe.\n",
    "\n",
    "Example input:\n",
    "\n",
    "`\n",
    "Trump said he received a call from Clinton shortly before he gave a victory speech early Wednesday in Manhattan.\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd048e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a news to predict whether is real or fake: Trump said he received a call from Clinton shortly before he gave a victory speech early Wednesday in Manhattan.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>96.11</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>95.00</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>93.98</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>86.66</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>80.35</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>73.33</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                models  accuracy predicted\n",
       "0        Random Forest     96.11      real\n",
       "1  Logistic Regression     95.00      real\n",
       "2        Decision Tree     93.98      real\n",
       "3          Naive Bayes     86.66      fake\n",
       "4                  KNN     80.35      real\n",
       "5                  SVM     73.33      real"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = input(\"Enter a news to predict whether is real or fake: \")\n",
    "res[\"predicted\"] = [sv_model.predict([user_input])[0], nb_model.predict([user_input])[0], lr_model.predict([user_input])[0], kn_model.predict([user_input])[0], dtc_model.predict([user_input])[0], rfc_model.predict([user_input])[0]]\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
